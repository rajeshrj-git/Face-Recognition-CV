{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969dabf1-68d3-42d4-8455-e6d9f24348d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependecies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0455ad4b-661b-4af1-8544-037e940cfa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d738986-b33a-452e-adc8-aa69ac1ff312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fa7f0d-9441-4eaa-8bce-7c4aefbadb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dir = r'E:\\Actors_images\\train_images'\n",
    "test_dir  = r'E:\\Actors_images\\test_images'\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32,(3,3), input_shape = (150,150,3), activation = 'relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64,(3,3), activation = 'relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(128,(3,3), activation = 'relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(512,activation = 'relu'),\n",
    "        Dense(3,activation = 'softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "adam = Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer = adam, loss= 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edca7817-7999-4f94-94a1-ab0abd778abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48b99796-9d6f-4589-bae7-2a8f13f54d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 images belonging to 3 classes.\n",
      "Found 41 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# num_classes = len(train_datagenerator.class_indices)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "image_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    width_shift_range  = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    rotation_range = 40,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# For Training\n",
    "train_datagenerator = image_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    "    \n",
    ")\n",
    "\n",
    "# For Validation\n",
    "validation_datagenerator = val_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32fd1c9a-b270-43b0-96cc-74b6bcb332d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39d3b66a-8803-4ffe-83db-0e2ccaa8bfa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.3963 - loss: 1.5362 - val_accuracy: 0.3902 - val_loss: 4.3861\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 985ms/step - accuracy: 0.4420 - loss: 2.4665 - val_accuracy: 0.3902 - val_loss: 1.2562\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 962ms/step - accuracy: 0.2640 - loss: 1.2063 - val_accuracy: 0.4390 - val_loss: 1.0871\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 964ms/step - accuracy: 0.4565 - loss: 1.0896 - val_accuracy: 0.3902 - val_loss: 1.0427\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 977ms/step - accuracy: 0.3799 - loss: 1.0574 - val_accuracy: 0.3902 - val_loss: 1.0265\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 947ms/step - accuracy: 0.4275 - loss: 1.0450 - val_accuracy: 0.4634 - val_loss: 1.0036\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.3416 - loss: 1.0792 - val_accuracy: 0.3902 - val_loss: 1.0650\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.4658 - loss: 1.0093 - val_accuracy: 0.6098 - val_loss: 0.9937\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 772ms/step - accuracy: 0.4959 - loss: 1.0092 - val_accuracy: 0.4146 - val_loss: 1.0110\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 954ms/step - accuracy: 0.3323 - loss: 1.0409 - val_accuracy: 0.5854 - val_loss: 0.9731\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 977ms/step - accuracy: 0.5725 - loss: 0.9899 - val_accuracy: 0.6098 - val_loss: 0.9473\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.6056 - loss: 0.9514 - val_accuracy: 0.6341 - val_loss: 0.9201\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 861ms/step - accuracy: 0.5394 - loss: 0.9716 - val_accuracy: 0.6341 - val_loss: 0.8961\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.5197 - loss: 0.9538 - val_accuracy: 0.6098 - val_loss: 0.8739\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.4565 - loss: 0.9719 - val_accuracy: 0.5854 - val_loss: 0.8750\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.5818 - loss: 0.9710 - val_accuracy: 0.6585 - val_loss: 0.8342\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 972ms/step - accuracy: 0.5476 - loss: 0.8896 - val_accuracy: 0.5854 - val_loss: 0.8848\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 907ms/step - accuracy: 0.5249 - loss: 0.8798 - val_accuracy: 0.6098 - val_loss: 0.8188\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 967ms/step - accuracy: 0.6056 - loss: 0.8597 - val_accuracy: 0.6098 - val_loss: 0.8231\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 895ms/step - accuracy: 0.6141 - loss: 0.8342 - val_accuracy: 0.6585 - val_loss: 0.7575\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 866ms/step - accuracy: 0.6390 - loss: 0.8006 - val_accuracy: 0.6829 - val_loss: 0.7413\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 970ms/step - accuracy: 0.6491 - loss: 0.8289 - val_accuracy: 0.7561 - val_loss: 0.6948\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 803ms/step - accuracy: 0.6744 - loss: 0.7920 - val_accuracy: 0.6585 - val_loss: 0.6740\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.6729 - loss: 0.7848 - val_accuracy: 0.7073 - val_loss: 0.6424\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 924ms/step - accuracy: 0.6159 - loss: 0.8813 - val_accuracy: 0.8780 - val_loss: 0.5950\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 954ms/step - accuracy: 0.6781 - loss: 0.6717 - val_accuracy: 0.7805 - val_loss: 0.5726\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.6201 - loss: 0.7608 - val_accuracy: 0.6829 - val_loss: 0.6248\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 820ms/step - accuracy: 0.5956 - loss: 0.7602 - val_accuracy: 0.8049 - val_loss: 0.5665\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 883ms/step - accuracy: 0.5562 - loss: 0.8993 - val_accuracy: 0.7805 - val_loss: 0.5419\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 941ms/step - accuracy: 0.6677 - loss: 0.7458 - val_accuracy: 0.6585 - val_loss: 0.6836\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.6159 - loss: 0.6867 - val_accuracy: 0.7805 - val_loss: 0.5321\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993ms/step - accuracy: 0.6967 - loss: 0.7173 - val_accuracy: 0.7561 - val_loss: 0.5970\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.6346 - loss: 0.7032 - val_accuracy: 0.7805 - val_loss: 0.5551\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 892ms/step - accuracy: 0.6929 - loss: 0.6327 - val_accuracy: 0.7805 - val_loss: 0.4946\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968ms/step - accuracy: 0.8126 - loss: 0.6876 - val_accuracy: 0.8537 - val_loss: 0.4488\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 816ms/step - accuracy: 0.7283 - loss: 0.7301 - val_accuracy: 0.7805 - val_loss: 0.4716\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 973ms/step - accuracy: 0.6636 - loss: 0.6455 - val_accuracy: 0.8293 - val_loss: 0.5107\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 940ms/step - accuracy: 0.6108 - loss: 0.8107 - val_accuracy: 0.8293 - val_loss: 0.4489\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 926ms/step - accuracy: 0.7453 - loss: 0.5593 - val_accuracy: 0.8780 - val_loss: 0.3941\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 994ms/step - accuracy: 0.7505 - loss: 0.5224 - val_accuracy: 0.9024 - val_loss: 0.4082\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 942ms/step - accuracy: 0.6729 - loss: 0.6846 - val_accuracy: 0.8049 - val_loss: 0.4282\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.8458 - loss: 0.4211 - val_accuracy: 0.8293 - val_loss: 0.4411\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.6542 - loss: 0.6747 - val_accuracy: 0.8780 - val_loss: 0.3683\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 943ms/step - accuracy: 0.6327 - loss: 0.6529 - val_accuracy: 0.6585 - val_loss: 0.6046\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 874ms/step - accuracy: 0.7034 - loss: 0.5521 - val_accuracy: 0.8537 - val_loss: 0.3812\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.7692 - loss: 0.4652 - val_accuracy: 0.8293 - val_loss: 0.4206\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968ms/step - accuracy: 0.6832 - loss: 0.6790 - val_accuracy: 0.8780 - val_loss: 0.3575\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 917ms/step - accuracy: 0.7692 - loss: 0.5222 - val_accuracy: 0.7805 - val_loss: 0.4998\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 781ms/step - accuracy: 0.7717 - loss: 0.5707 - val_accuracy: 0.9024 - val_loss: 0.3725\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 994ms/step - accuracy: 0.9420 - loss: 0.4069 - val_accuracy: 0.9024 - val_loss: 0.3676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f96e2a3280>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    train_datagenerator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_datagenerator,\n",
    "    validation_steps=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c12fc1f6-9521-4233-9146-80005e1047b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feef5196-2143-4e8d-8c17-cb9391a0079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\rajes\\Datascience_jp\\Day28-Recognition & Transformers\\Face_Recognition_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fb2aae4-1ad8-431a-ae16-54efa35b70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognition For new Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ad0b0eb-b63a-4527-b2ae-91d8c303df38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "Predicted Actor is Rajesh\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Load the model\n",
    "model_loaded = load_model(r'C:\\Users\\rajes\\Datascience_jp\\Day28-Recognition & Transformers\\Face_Recognition_CNN.h5')\n",
    "\n",
    "class_indices = train_datagenerator.class_indices\n",
    "class_indices = {v:k for k,v in class_indices.items()}\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image , (150,150))\n",
    "    image = np.expand_dims(image, axis = 0) /255.0\n",
    "    prediction = model_loaded.predict(image)\n",
    "    class_index = np.argmax(prediction,axis = 1)[0]\n",
    "    class_label = class_indices[class_index]\n",
    "    return class_label\n",
    "\n",
    "new_image = r\"E:\\Actors_images\\train_images\\Tony Stark\\9b9f752fc3b658076e6b8ebc454f3819.jpg\"\n",
    "prediction = predict_image(new_image)\n",
    "\n",
    "print(f'Predicted Actor is {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37427f9f-36f7-41c6-b5e4-3f2595a7c3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f964280d-b181-477d-a0a6-bc9447719aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af6e2e-6c0d-4d66-969c-266d27e93aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e0e15a-2591-414a-9f05-aef56d4a72e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
